{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"logo.png\" height=\"900\"> \n",
    "</center>\n",
    "\n",
    "\n",
    "# Arriva, ой то есть ARIMA\n",
    "\n",
    "Все хотят знать, что же будет дальше с экономикой. Из-за этого люди активно придумывают и строят всякие индикаторы, которые должны помочь понять, когда начнётся кризис. В этом задании вам предстоит проанализировать несколько подобных индикаторов и выяснить правда ли они улучшают прогнозы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Краткая история\n",
    "\n",
    "__Про ручные индексы__\n",
    "\n",
    "Экономисты хотят понимать насколько сильно люди верят в прекрасное экономическое будущее. Для этого они проводят социальные опросы: просят оценить насколько люди доверяют банкам, спрашивают есть ли у них инвестиции в ценные бумаги и тп. В итоге ответы на эти вопросы превращаются в индекс потребительских настроений. \n",
    "\n",
    "Первым такую штуку начал делать Мичиганский университет. Он спрашивает $500$ потребителей. Каждому задаёт $5$ вопросов, касающихся их финансового положения и мнения о нынешнем состоянии (2 вопроса) и будущем (3 вопроса) экономики. Берется процентная доля респондентов, отметивших улучшение экономических условий, из нее вычитается доля тех, кто заявил, что стало хуже, к полученному числу прибавляется 100. Из ответов на первые 2 вопроса формируется обзор нынешнего экономического положения, из последних $3$-х — индекс потребительских ожиданий. Таким образом, ожидания отвечают примерно за $60\\%$ индекса. Расчёт индекса делается дважды в месяц.\n",
    "\n",
    "В России по аналогичной методике \"Левада-центр\" начал считать свой индекс потребительских натсроений. На его динамику даже можно посмотреть [у них на сайте.](https://www.levada.ru/indikatory/sotsialno-ekonomicheskie-indikatory/) На самом деле, сейчас социологи считают довольно много подобных индексов. Тот же самый [PMI (индекс деловой активности)](https://ru.wikipedia.org/wiki/Индекс_деловой_активности) - один из возможных вариантов. \n",
    "\n",
    "Такие индексы можно пытаться использовать для того, чтобы улучшить прогнозы разных макроэкономических рядов вроде безработицы. И люди активно пытаются это делать. Проблема заключается в том, что нужно тратить много ресурсов на то, чтобы сделать социальный опрос. Плюс социальные опросы можно делать редко. Хочется, чтобы было быстро, дёшево и часто.\n",
    "\n",
    "__Про автоматические индексы__\n",
    "\n",
    "Выход есть. Нужно заглянуть в интернет. Любая поисковая система собирает статистику, связанную с запросами пользователей. Более того, частично такая статистика [находится в открытом доступе.](https://trends.google.ru/trends/?geo=RU) Это позволяет собирать информацию о том, чем интересовались люди и на её основе делать какие-то выводы.\n",
    "\n",
    "Например, в 2013 году Google заявил, что с помощью информации из поисковых запросов о трейлерах, он может с низкой MAPE предсказывать кассовость ленты в первые дни показа. Поисковые запросы используют для предсказания распространения эпидемий гриппа и даже ковида.\n",
    "\n",
    "По аналогии можно узнать, чем люди интересуются во время кризиса, а дальше попытаться отслеживать такие запросы и понимать, насколько сильно колеблется их обеспокоенность. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Данные \n",
    "\n",
    "В табличке ниже вам даны несколько индексов потребительских настроений и несколько переменных для прогнозирования: \n",
    "\n",
    "- `levada_IPN` - индекс потребительских настроений, который строится на основе социальных опросов Левада-центром. Отражает то, насколько сильно люди доверяют экономике.\n",
    "- `poiskInd_corr`- индекс поиска, отражает то, насколько сильно люди обеспокоенны тем, что происходит с экономикой. Он построен на основе поисковых запросов. Как именно - для задания неважно, но подробнее об этом можно почитать [в статье про подобные индексы.](https://rjmf.econs.online/2020/4/forecasting-macroeconomic-indicators-news-and-search-queries/)\n",
    "\n",
    "- `USD` - динамика курса доллара\n",
    "- `RTRD` - оборот розничной торговли (текущие цены, млрд. рублей)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.tsv', sep='\\t')\n",
    "df.set_index('fielddate', inplace=True)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "выбросим все стоки с пропусками и будем рассматривать индексы на одном и том же временном промежутке. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['poiskInd_corr', 'levada_IPN']].plot(figsize=(10,5));\n",
    "\n",
    "plt.title('Динамика индексов настроений');\n",
    "plt.xlabel(\"Месяц\")\n",
    "plt.ylabel(\"Индекс\")\n",
    "plt.legend(fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что в период кризиса индекс доверия Левады падает. Индекс обеспокоенности, построенный по гуглу, растёт. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Предварительный анализ рядов\n",
    "\n",
    "Проанализируем динамику валютного курса и оборота розничной торговли более детально."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(2, 1, figsize=(12,10))\n",
    "\n",
    "df['USD'].plot(ax=axes[0]);\n",
    "df['RTRD'].plot(ax=axes[1]);\n",
    "\n",
    "axes[0].set_title(\"Динамика курса\")\n",
    "axes[1].set_title(\"Динамика розничной торговли\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Видим, что динамика валютного курса нестационарна. У нас есть два математических ожидания. В динамике ряда нет ни тренда ни сезонности.\n",
    "- В динамике розничной торговли есть тренд и сезонность.  \n",
    "\n",
    "__[а] Проверьте гипотезу о стационарности рядов с помощью KPSS и ADF тестов на уровне значимости $5\\%$. В качестве ответа в переменнык `pval` запишите соотвествующие p-value.__ Обратите внимание, что в динамике розничной торговли есть константа и тренд. В динамике курса есть константа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "60230ed35ed804f92a16f5bce9bd5593",
     "grade": false,
     "grade_id": "cell-0d41ef8c228d48d9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "\n",
    "### ╰( ͡° ͜ʖ ͡° )つ▬▬ι═══════  bzzzzzzzzzz\n",
    "# will the code be with you\n",
    "\n",
    "pval_usd_kpss = ...\n",
    "pval_rtrd_kpss = ...\n",
    "\n",
    "pval_usd_adf = ...\n",
    "pval_rtrd_adf = ...\n",
    "\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0c35e7c50024f5ef4030040b93fafdd1",
     "grade": true,
     "grade_id": "cell-5c73e3a0968d0f3b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.abs(pval_usd_kpss - 0.01) < 1e-2\n",
    "assert np.abs(pval_usd_adf - 0.77) < 1e-2\n",
    "\n",
    "# несколько похожих скрытых тестов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оба ряда оказались на уровне значимости $5\\%$ нестационарными по всем тестам. \n",
    "\n",
    "__[б]__ Возьмите первую разность от валютного курса методом `.diff()`. Для оборота розничной торговли возьмите $12$-ую, сезонную разность. Изобразите динамику разностей на картике. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "87657233975e611db1887c52413213b6",
     "grade": false,
     "grade_id": "cell-61d0bf9a1c9ba5bc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ▬▬ι═══════  bzzzzzzzzzz\n",
    "# will the code be with you\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверьте ADF-тестом гипотезу о стационарности рядов на уровне значимости $5\\%$. В соотвествующие переменные запишите `pvalue` тестов. Обратите внимание, что для курса у нас нет ни константы, ни тренда. Для оборота торговли есть константа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "be690fa81040c9c61bca8cac6a3cf233",
     "grade": false,
     "grade_id": "cell-f808ccbd89e1aa1c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ▬▬ι═══════  bzzzzzzzzzz\n",
    "# will the code be with you\n",
    "\n",
    "pval_diff_usd = ...\n",
    "pval_diff_rtrd = ...\n",
    "\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "57f5dad7a31acdfe0bdbc7134e6f203f",
     "grade": true,
     "grade_id": "cell-c03168d82f998599",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert pval_diff_usd < 1e-10\n",
    "\n",
    "# несколько похожих скрытых тестов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обоих рядов гипотеза о наличии единичного корня отвергается. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Посмотрим внимательнее на динамику разностей валютного курса. Возникает ощущение, что в конце $2014$ - $2015$ годах дисперися валютного курса была больше, чем в другие периоды времени. Это связано с [валютным кризисом](https://ru.wikipedia.org/wiki/Валютный_кризис_в_России_(2014—2015)) и тем, что с этого момента ЦБ сфокусировался на таргетировании инфляции. Такой разброс в дисперсии будет приводить к тому, что предпосылки ARIMA-модели не будут выполняться. Из-за этого будут портиться доверительные интервалы. Можно стабилизировать дисперсию преобразованием Бокса-Кокса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[в]__ Обучите на исходном ряде для курса преобразование Бокса-Кокса, если подзабыли что это за преобразование, пересмотрите лекцию про это из самого первого курса :) Возьмите первые разности, нарисуйте ряд на картинке, стала ли ситуация с дисперсией визуально лучше?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c0dcba30aa8b5f7e9a8842074c9f9d86",
     "grade": false,
     "grade_id": "cell-6ba992d3edd386fd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from pmdarima.preprocessing import BoxCoxEndogTransformer\n",
    "\n",
    "### ╰( ͡° ͜ʖ ͡° )つ▬▬ι═══════  bzzzzzzzzzz\n",
    "# will the code be with you\n",
    "\n",
    "transformer = ... \n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a0fec9303f4b581877e8e96e18316f9b",
     "grade": true,
     "grade_id": "cell-d73fd40abaf0cfbe",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.abs(transformer.lam1_ + 0.447) < 1e-3\n",
    "\n",
    "# Тут нет скрытых тестов :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. ARIMA-модель\n",
    "\n",
    "Разобьём выборку на тренировочную и тестовую, а затем обучим ARIMA-модель. \n",
    "\n",
    "1. Параметры `p,q` перебирайте от 0 до 5 включительно, `P,Q` от 1 до 3\n",
    "2. Параметр `seasonal` выставите в `true` с `m=12`\n",
    "3. Параметры `max_D, max_d` потавьте равными 2\n",
    "4. Парааметр `max_order` выставите в 10\n",
    "5. В поле `information_criterion` выберите для выбора моделя критерий Шварца (`bic`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "85e1d81569c0b2ac3a240cb8fcf97a71",
     "grade": false,
     "grade_id": "cell-1e4b536071e68d4f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pmdarima as pm\n",
    "\n",
    "def train_arima(y, test_size=36):\n",
    "    y_train, y_test = y[:-test_size], y[-test_size:]\n",
    "    \n",
    "    arima_model = pm.auto_arima(\n",
    "        y_train,\n",
    "        \n",
    "        # ??? \n",
    "        \n",
    "        trace=True)\n",
    "    \n",
    "    # your code here\n",
    "    \n",
    "    return arima_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустите код для обучения. Обратите внимание, что перебираться будут не все модели. Так происходит из-за того, что в опциях модели выставлено `stepwise=True`. Это специальный алгоритм для более быстрого перебора гипер-параметров. Его разработали в 2008 годую. Подробнее [в документации.](https://alkaline-ml.com/pmdarima/modules/generated/pmdarima.arima.auto_arima.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rtrd = train_arima(df.RTRD.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_usd = train_arima(df.USD.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rtrd.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_usd.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишите в переменные`ans1` и `ans2` порядок $AR$ и $MA$ частей лучшей модели для оборот арозничной торговли. В переменные `ans3` и `ans4` запишите аналогичный результат для валютного курса. \n",
    "\n",
    "> __ВАЖНО!!!__ Перед отправкой тетрадки в грейдер на оценивание закомментируйте код, который обучает модели. Оставьте только ответы, записанные в соотвествующие переменные. При выставлении оценки ваш код должен отрабатывать за 30 секунд. Из-за того, что модель обучается довольно долго, полноценный код процедуру тестирования не пройдёт."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4396ef923b22e2deade01f0716117cf9",
     "grade": false,
     "grade_id": "cell-d0bea220af4e6a5e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ▬▬ι═══════  bzzzzzzzzzz\n",
    "# will the code be with you\n",
    "ans1 = ...\n",
    "ans2 = ...\n",
    "ans3 = ...\n",
    "ans4 = ...\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2916c451930dc4d97d0b4271eaf63797",
     "grade": true,
     "grade_id": "cell-a5c4f4997585989e",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert ans1 == 0\n",
    "\n",
    "# несколько похожих скрытых тестов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте протоколы для диагностики получившихся моделей. __Устно ответьте на вопросы:__ всё ли нормально с остатками? Можно ли использовать эти модели для прогнозирования? А для строительства доверительных интервалов? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "70464e0c000c861942a089b40080a5a5",
     "grade": false,
     "grade_id": "cell-bf53f4b4060312cb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ▬▬ι═══════  bzzzzzzzzzz\n",
    "# will the code be with you\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Внимательно изучите код, написанный ниже. Он строит Leave One Out прогнозы. Сначала обучение идёт на `y_train`. Прогноз строится на один период вперёд. Затем одно наблюдение из `y_test` добавляется в `y_train` и та же модель обучается на новой выборке. Прогноз строится ещё на одно наблюдение вперёд. Так продолжается до тех пор, пока не кончится выборка `y`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima import model_selection\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "def loo_cv(model, y, test_size=36):\n",
    "    \n",
    "    y_train, y_test = y[:-test_size], y[-test_size:]\n",
    "\n",
    "    # метод, который строит прогнозы по заданному внутри правилу\n",
    "    cv = model_selection.SlidingWindowForecastCV(\n",
    "        window_size=y_train.size,   # начинаем с трейновой выборки \n",
    "        step=1,                     # шаг между фолдами для обучения \n",
    "        h=1                         # на сколько шагов вперёд каждый раз строить прогноз\n",
    "    )\n",
    "\n",
    "    predicts_noIndex = model_selection.cross_val_predict(\n",
    "        model, y, # идём получившейся arima_model по y \n",
    "        cv = cv,        # по правилам, заданным выше строим прогнозы \n",
    "    )\n",
    "    \n",
    "    return predicts_noIndex, mae(y_test, predicts_noIndex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя функцию, написсанную выше, постройте прогнозы для курса доллара и оборота розничной торговли. Замерьте качество получившихся прогнозов с помощью метрики MAE. Запишите получившиеся результаты в переменные `mae_usd` и `mae_rtrd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c4d52b0fe212c15c42e8e952eb0e5a3e",
     "grade": false,
     "grade_id": "cell-3fc8616933e40977",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ▬▬ι═══════  bzzzzzzzzzz\n",
    "# will the code be with you\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изобразите получившиеся прогнозы и исходный ряд на одной картинке. Можно попрбовать использовать для этого функцию `plot_series` из пакет `sktime`. Не забудьте установить его в своё текущее локальное окружение по аналогии с тем, как ммы это сделали для предыдущей домашней работы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "69826f3c3be02792b48189efa44cb397",
     "grade": false,
     "grade_id": "cell-6481a9115e838ebe",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ▬▬ι═══════  bzzzzzzzzzz\n",
    "# will the code be with you\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __ВАЖНО!!!__ Перед отправкой тетрадки в грейдер на оценивание закомментируйте код, который обучает модели. Оставьте только ответы, записанные в соотвествующие переменные. При выставлении оценки ваш код должен отрабатывать за 30 секунд. Из-за того, что модель обучается довольно долго, полноценный код процедуру тестирования не пройдёт."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. ARIMA с экзогенными переменными\n",
    "\n",
    "Теперь давайте добавим в качестве экзогенной переменной в нашу модель лаги индексов неопределённости. Если бы у нас была модель $ARMA(1,1)$ и мы бы захотели добавить в неё экзогенную переменную $x_{t-1}$, модель выглядела бы так:\n",
    "\n",
    "$$\n",
    "y_t = \\mu + \\beta \\cdot  y_{t-1} + \\alpha \\cdot \\varepsilon_{t-1} + \\varepsilon_t + \\gamma \\cdot x_{t-1} \n",
    "$$\n",
    "\n",
    "Экзогенных переменных можно добавить сколько угодно. Для этого у модели есть отдельный параметр. Он на вход принимает матрицу. Для удобства всю процедуру оценки модели завернём в функцию. Внимательно изучите, чем именно эта функция отличается от предыдущей. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loo_cv_with_index(model, y, x, test_size=36):\n",
    "    \n",
    "    y_train, x_train = y[:-test_size], x[:-test_size]    \n",
    "    y_test, x_test = y[-test_size:], x[-test_size:]\n",
    "\n",
    "    cv = model_selection.SlidingWindowForecastCV(\n",
    "        window_size=y_train.size, \n",
    "        step=1, \n",
    "        h=1\n",
    "    )\n",
    "\n",
    "    predicts = model_selection.cross_val_predict(\n",
    "        model, y,\n",
    "        exogenous = np.array([x]).T,\n",
    "        cv=cv\n",
    "    )\n",
    "    \n",
    "    return predicts, mae(y_test, predicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшую модель мы подобрали. Давайте попробуем добавить в неё в качестве экзогенной переменной наши индексы неопределённости. Это поможет нам увидеть, правда ли эти индексы улучшают качество прогнозов.\n",
    "\n",
    "### Оборот розничной торговли\n",
    "\n",
    "Добавим текущее значение индекса. Если качество прогноза вырасте, это означает, что текущий индекс содержит в себе информацию о том, что произошло в экономике прямо сейчас. Для прогнозирования это бесполезно, но показывает насколько сильно наш индекс может объяснить ситуацию в экономике.\n",
    "\n",
    "> Код ниже может работать довольно долго. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.RTRD.values\n",
    "x = df.levada_IPN.values\n",
    "\n",
    "predicts_levada_rtrd, mae_rtrd_2 = loo_cv_with_index(model_rtrd, y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.RTRD.values\n",
    "x = df.poiskInd_corr.values\n",
    "\n",
    "predicts_poisk_rtrd, mae_rtrd_3 = loo_cv_with_index(model_rtrd, y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Оригинальная модель: {mae_rtrd}')\n",
    "print(f'Модель с индексом Левады: {mae_rtrd_2}')\n",
    "print(f'Модель с индексом поиска: {mae_rtrd_3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Индекс Левады улучшил прогноз оборота розничной торговли. Индекс поиска ухудшил. Попробуем посмотреть, получится ли у нас предсказывать по текущему значению индекса будущее значение оборота розничной торговли."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.RTRD.values[1:]\n",
    "x = df.levada_IPN.shift(1).values[1:] # shift это сдвиг на 1 вперёд, мы же предсказываем лагом\n",
    "\n",
    "predicts_levada_rtrd, mae_rtrd_2 = loo_cv_with_index(model_rtrd, y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.RTRD.values[1:]\n",
    "x = df.poiskInd_corr.shift(1).values[1:] # shift это сдвиг на 1 вперёд, мы же предсказываем лагом\n",
    "\n",
    "predicts_poisk_rtrd, mae_rtrd_3 = loo_cv_with_index(model_rtrd, y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Оригинальная модель: {mae_rtrd}')\n",
    "print(f'Модель с индексом Левады: {mae_rtrd_2}')\n",
    "print(f'Модель с индексом поиска: {mae_rtrd_3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что оба индекса ухудшили прогнозы :( "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Курс валюты \n",
    "\n",
    "Проделаем такую же операцию с валютным курсом. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.USD.values\n",
    "x = df.levada_IPN.values\n",
    "\n",
    "predicts_levada_usd, mae_usd_2 = loo_cv_with_index(model_usd, y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.USD.values\n",
    "x = df.poiskInd_corr.values\n",
    "\n",
    "predicts_poisk_usd, mae_usd_3 = loo_cv_with_index(model_usd, y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Оригинальная модель: {mae_usd}')\n",
    "print(f'Модель с индексом Левады: {mae_usd_2}')\n",
    "print(f'Модель с индексом поиска: {mae_usd_3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видго, что оба индекса содержат информацию о том, какие значения курс принял прямо сейчас. Попробуем посмотреть, можно ли прогнозировать курс с помощью запаздывания лучше, чем обычной ARIMA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.USD.values[1:]\n",
    "x = df.levada_IPN.shift(1).values[1:] # shift это сдвиг на 1 вперёд, мы же предсказываем лагом\n",
    "\n",
    "predicts_levada_usd, mae_usd_2 = loo_cv_with_index(model_usd, y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.USD.values[1:]\n",
    "x = df.poiskInd_corr.shift(1).values[1:] # shift это сдвиг на 1 вперёд, мы же предсказываем лагом\n",
    "\n",
    "predicts_poisk_usd, mae_usd_3 = loo_cv_with_index(model_usd, y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Оригинальная модель: {mae_usd}')\n",
    "print(f'Модель с индексом Левады: {mae_usd_2}')\n",
    "print(f'Модель с индексом поиска: {mae_usd_3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что индекс поиска улучшил прогнозы. Индекс Левады не привёл к улучшению. \n",
    "\n",
    "__Выводы:__ индексы поиска и Левады содержут информацию о том, что в данный момент происходит в экономике. Их текущее значение помогает предсказать, что происходит прямо сейчас в экономике. На практике это бесполезно. Мы хотим по вчерашнему значению индекса спрогнозировать, что произойдет завтра. Видно, что это можно сделать для курса доллара с помощью индекса поиска.\n",
    "\n",
    "Обратите внимание, что данные у нас месячные. Если бы частота данных была бы повыше, эффект от добавления индексов в модели мог бы быть сильнее. Но это требует отдельного исследования :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте, по аналогии с тем, что было сделано выше, добавить в модель в качестве экзогенных переменных сразу оба индекса. Насколько сильно это улучшает прогноз? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ▬▬ι═══════  bzzzzzzzzzz\n",
    "# will the code be with you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __ВАЖНО!!!__ Перед отправкой тетрадки в грейдер на оценивание закомментируйте код, который обучает модели. Оставьте только ответы, записанные в соотвествующие переменные. При выставлении оценки ваш код должен отрабатывать за 30 секунд. Из-за того, что модель обучается довольно долго, полноценный код процедуру тестирования не пройдёт."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Бонусный трэк:\n",
    "\n",
    "- Попробуйте взять в качестве дополнительных экзогенных переменных сразу же и индекс поиска и индекс Левада-центра. \n",
    "- Выше мы сказали, что у валютного курса не самая стабильная дисперсия. Соберите пайплайн, в котором первым шагом метод Бокса-Кокса будет стабилизировать дисперсию. Обучите обе модели и посмотрите что происходит с качеством прогнозов. \n",
    "- По картинкам для диагностики модели видно, что в данных есть выброс. Можно попробовать изолировать его с помощью экзогенной дамми-переменной, если хочется добиться идеального выполнения предпосылок. \n",
    "- Если вас заинтересовали индексы неопределённости, можно посмотреть [статью автора курса про такие индексы бывают с кучей ссылок и кодом](https://github.com/FUlyankin/uncertainty_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ▬▬ι═══════  bzzzzzzzzzz\n",
    "# will the code be with you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
